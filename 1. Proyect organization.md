# 1. Project organization

## Testing

> **TL;DR**
>
> - Write tests. They can be run by hand, but always define tests for your code.

Tests allow you to validate the code does what's expected, and without them we
can consider the code behaviour random and by definition "broken". They are the
most useful, and at the same time the most infravalued, code you can write. This
is because writting good tests consume time, and it's code that will not be
running later in production, but they would help you to find bugs and errors
earlier and reduce develop time in the long term. Consider them part of the
code you write, and do both your code and its tests at the same time.

Ideally tests should be automated and replicable, but sometimes define the tests
environment can be complicated, for example when they involve actions in the
real world, like print a document. In that contexts, it's easier to consider
tests in a more wide sense like a list of validations that needs to pass each
time the tests are check. This can be implemented as a simple checklist or
bullet points and be given to another person (like a QA department) to validate
them by hand, and when oportunity arise automate them to make the testing stage
easier and faster.

Regarding automated test frameworks, there are several ones for Node.js, but the
*de-facto* current standard is [jest](https://jestjs.io/). Developed by
Facebook, it's a one-stop framework that holds capabilities of both testing
framework, tests runner, assertions and code coverage, and also it support
testing async functionality when the test return a Promise. It's very focused
to be used with [React](https://reactjs.org/), so the default environment it
uses is browser-like based on [JsDOM](https://github.com/jsdom/jsdom), if you
want to use a real Node.js environment (for example, to use Javascript features
available in latests versions of Node.js), use the
[testEnvironment](https://jestjs.io/docs/en/configuration#testenvironment-string)
option set to `node`.

### Unit tests, and acceptance tests

> **TL;DR**
>
> - Do the tests only against the public API (*acceptance tests*).

Probably you've read about *unit tests* in the past, but there's a bit of
confussion here, and probably you would not need them. Unit testing regards to
fine-grain testing of all the component methods and behaviour, that's overkill
and froze the code details, and sometimes is useless.

What's more people really need (and some times misnames as *unit tests*) are
*acceptance tests*: tests done against the public API of your component,
whatever is it. If you are writting a class, its public API are its public
methods; if you are writting a REST API, its public API are its web endpoints.
You don't need to worry about the internal details how they are done, just only
that when you call them, you receive the expected result. This make tests a bit
more dificult to write if the use cases/stories are complex, but provides more
fidelity about how the components are going to be used (at the same time the
code coverage is already being improved), isolate the tests from the
mplementation (tests can be reused if libraries are changed, and in some cases,
also when changing programming languages too), helps to improve actual APIs to
make them more usable, and helps to identify whats parts of the code are not
accesible from the public API (garbage code) and could be removed instead of
writting tests for them.

If you need to do unit tests for specific behaviour of a private component,
move that component to a new module, or also consider to move it to an external
package and use it as a dependency and implementation detail. This way, that
private components becames the public API of the new module/package, so you can
write acceptance tests against it.

#### Code coverage

> **TL;DR**
>
> - Check tests code coverage. Under 80% is garbage, try to achieve 100%.

Code coverage is an important part of tests, since it helps you to identify what
lines of your code are untested, and in some cases what decision branches in
your code logic are tested and what ones not. `Jest` provide support for that,
but it's disabled by default. To enable it, you can use the `--coverage` flag,
and will show some code coverage statistics after passing the tests. By default,
`jest` only collect coverage info from the files that has tests for, if you want
to be sure all your project files are tested, use the
[collectCoverageFrom](https://jestjs.io/docs/en/configuration#collectcoveragefrom-array)
config option.

#### Isolate tests environment

> **TL;DR**
>
> - Isolate your tests, don't depend on external infraestructure to run them.
> - If you need infraestructure for your tests, they are *integration tests*.

One common pitfall when writting unitary and acceptance tests is that they are
testing our own code, but still accessing third party infraestructure. This can
lead to problems from tests not passing because the network is not available
(i.e. developing in a plane) to adding garbage data in real databases (in
development stage, or in production), incurring in costs each time tests are
being executing (i.e. sending confirm SMSs for a login system), or needing some
external hardware like a ticketing printer or a barcode scanner.

To deal with this, there are options like dependencies injection usual in other
languages, but over complicated in Javascript. In that case, it's better to use
mocks, both by allowing to pass an optional argument to the class constructors
about what object instance you want to use (but allowing it to create a regular
one by default) and setting it to the mock object during the tests, or use an
already available mock or dumb object for the service or device you want to use.

To mock HTTP requests to external servers when testing a client, the best tool
is [nock](https://github.com/nock/nock). It allow to capture real requests to
HTTP servers like third party APIs and later in your tests intercept them and
return instead the recorded data, or any one you provide it. On the other hand,
if what you are testing is a server, it's counterpart is
[supertest](https://github.com/visionmedia/supertest), that allow to customize
HTTP request and do expectations about its output. It can work with Promises, so
it integrates really well with `jest`.

Databases are a more complicate subject, because usually they are a standalone
server, so they should be considered *integration tests*, but are tightly
coupled with the application code, also when databases accesses are acotated to
a single file or group of files. When they offer an HTTP interface it's possible
to `nock` as explained before. In other cases, the traditional solution has been
to require to spin up a local database server before running the tests and use
them. This is a somewhat good idea, but have the problem of filling the database
with garbage and waste space or get bad results due to old data. In the case of
MongoDB database, it's better to use some tool like
[MongoBox](https://github.com/piranna/mongobox.js), that each time starts an
in-memory empty instance of MongoDB in a random TCP port, so there's no conflict
with other previous servers (and also can start several instances at the same
time) and you can fill it with the fixtures needed for each one of the tests,
having a deterministic and controlled tests environment.

For other components like WebSocket servers or when your tests require some
external hardware, there are some modules that can be useful available in
[npm registry](https://www.npmjs.com), it's just a matter of search for the one
that bests fits. If not, you can try to write some dumb objects that mimick
their behaviour or the one of their interfaces (maybe writing the data with some
delays, or logging it to the console or to a file for later inspection), and
set your code to use them.

Finally, if you definitelly need to connect to other real servers or systems,
then they can not be considered unitary or acceptance test, since they are
testing the integration with other systems. These *integration tests* usually
are slower and more time expensive due to being more in detail, and could
have some associated costs too by using these real systems, so they should be
run only in a *Continuous Integration* server, for example each time you upload
your code using `git push`.

### Integration tests

> **TL;DR**
>
> - Wirte *integration tests* using real infraestructure in an umbrella project.




. This is sometimes fixed by
fix the




### System tests

> **TL;DR**
>
> - Implement *system tests* to be sure everything works after deployment.



## Linting

> **TL;DR**
>
> - Use a linter and code style. Whatever you want, also your own, but use one.

Code linting checks (and sometimes fix) your code style, making it uniform and
homogeneous. This makes it easier to read but also allow to detect some pitfalls
like undeclared variables or garbage (unused) code and variables.

One of the most popular linter is [eslint](https://eslint.org/). It's very
configurable and already provide some recomended style rules that can be used as
basis, but you can use any other recomended style rules
([AirBnB](https://www.npmjs.com/package/eslint-config-airbnb) is very popular).
If you don't want to think about style, [standard JS](https://standardjs.com/)
and [semistandard](https://github.com/standard/semistandard) if you don't want
to use semicolons after each statement are two config-less options.

## Documentation

> **TL;DR**
>
> - Always write documentation in english.
> - Use a standard format. In case of doubt, Markdown is easy to read and write.






limit tests timeout

main -> /lib/routes
/app.js
/server.js

package version

.eslintignore

"quote-props": ["error", "as-needed"],


Don't embed test data in tests, assign it first to a variable, or if possible, use fixtures

git hooks to run tests on `pre-commit` and `pre-push`
Git hooks to run linting and tests and generate docs before each commit and push. If tests are heavy, only linting and docs for commits is fine, but tests are mandatory before push

Check actual returned value on tests, not only status
